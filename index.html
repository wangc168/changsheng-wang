<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yihua Zhang</title>
    <meta name="author" content="Yihua  Zhang" />
    <meta name="description" content="Don't waste your life. Don't waste it.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>‚òØÔ∏è</text></svg>">
    
    <link rel="stylesheet" href="/changsheng-wang/assets/css/main.css">
    <link rel="canonical" href="https://changsheng-wang.github.io/changsheng-wang/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/changsheng-wang/assets/js/theme.js"></script>
    <script src="/changsheng-wang/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class=" sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <!-- Social Icons -->
          <div class="navbar-brand social">
            <a href="mailto:%7A%68%61%6E%31%39%30%38@%6D%73%75.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=ui-pcWgAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/normaluhr" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/zhangyihua" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/zyh2022" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            <a href="./assets/img/Wechat.jpg" title="WeChat"><i class="fa fa-wechat"></i></a>
            

          </div>
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/changsheng-wang/">About<span class="sr-only">(current)</span></a>
              </li>
              
              <!-- Blogs -->
              <li class="nav-item">
                <a class="nav-link" href="https://normaluhr.github.io" target="_blank" rel="noopener noreferrer noopener noreferrer">Blogs</a>
              </li>

              <!-- CV -->
              <li class="nav-item">
                <a class="nav-link" href="./CV_Yihua_Zhang.pdf" target="_blank" rel="noopener noreferrer">CV</a>
              </li>
              
              <!-- Blog -->
              <!-- Uncomment below to use in-site blogs -->
              <!--  -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/blog/">Posts</a>
              </li> -->
              <!-- -->

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/collaboration/">Collaboration</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/photos/">Photos</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           Yihua Zhang
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/vanishing_me-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/vanishing_me-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/vanishing_me-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/vanishing_me.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="vanishing_me.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

            <div class="address">
              <p>Room 3210 </p> <p>428 S Shaw LN</p> <p>East Lansing, Michigan</p> <p>United States of America</p> <p>             </p> <p>             </p>

            </div>
          </div>

          <div class="clearfix">
            <p>Yihua Zhang (Âº†ÈÄ∏È™Ö) is a fourth-year Ph.D. student at <a href="https://www.optml-group.com/" target="_blank" rel="noopener noreferrer">OPTML Group</a> at Michigan State University, under the supervision of <a href="https://lsjxjtu.github.io/" target="_blank" rel="noopener noreferrer">Prof. Sijia Liu</a>. His research centers on <em>trustworthy</em> and <em>scalable</em> machine learning (ML) algorithms for large language models (LLMs) and diffusion models (DMs), with a keen focus on bridging theoretical foundations and real-world applications. In recognition of his outstanding contributions, Yihua was honored with the <a href="https://research.ibm.com/university/awards/fellowships-awardees.html" target="_blank" rel="noopener noreferrer">IBM PhD Fellowship 2024</a>, the <a href="https://cpal.cc/rising_stars_guidelines/" target="_blank" rel="noopener noreferrer">CPAL 2025 Risiting Star Award</a>, and the prestigious <a href="https://mlcommons.org/2024/06/2024-mlc-rising-stars/" target="_blank" rel="noopener noreferrer">MLCommons Rising Star Award in 2024</a>. Yihua has gained valuable industry experience through internships at leading technology companies such as <a href="https://ai.meta.com/" target="_blank" rel="noopener noreferrer">Meta AI</a>, <a href="https://aws.amazon.com/ai/" target="_blank" rel="noopener noreferrer">Amazon AWS AI Lab</a>, and <a href="https://research.cisco.com/" target="_blank" rel="noopener noreferrer">Cisco Research</a>. Yihua‚Äôs work is driven by the need to develop efficient, scalable, and robust ML algorithms, with a commitment to addressing modern challenges in these domains.</p>

<p><strong>Research Keywords</strong>: Machine Unlearning, Jailbreak Attack, Adversarial Training, Fairness, Parameter-Efficient Fine-Tuning, Memory-Efficient Fine-Tuning, Mixture-of-Experts, Model Sparsity, Large Language Model, Diffusion Model, Bi-Level Optimization, Zeroth-Order Optimization.</p>

<p><img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> <strong>Theme 1: Trustworthy Foundation Models: Robustness, Fairness, and Unlearning</strong>: Yihua explores how to enhance the trustworthiness of foundation models, focusing on robustness against adversarial attacks, fairness in decision-making, and the emerging area of machine unlearning to ensure data privacy and compliance with deletion requests.</p>

<p><img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> <strong>Theme 2: Scalable Foundation Models: Efficient Models, Data, and Algorithms</strong>: In this theme, Yihua‚Äôs work revolves around designing models that are not only powerful but also computationally efficient. His research includes advancements in model sparsification, memory-efficient fine-tuning techniques, and optimizing data usage for large-scale models.</p>

<p><img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> <strong>Theme 3: Optimization in Modern ML: Bi-Level and Zeroth-Order Optimization</strong>
This research line focuses on the theoretical underpinnings of scalable machine learning algorithms, addressing real-world constraints through bi-level optimization and zeroth-order optimization.</p>

<p><strong>Collaboration Opportunities</strong></p>

<p>I am always open to collaborations with researchers, as well as undergraduate and graduate students seeking Ph.D. positions. While my primary research focuses on trustworthy and scalable ML algorithms for LLMs and DMs, I am also interested in exploring a wide range of topics beyond these areas. If you have exciting research ideas or are looking for opportunities to conduct research under professional guidance, feel free to reach out to me. Please refer to my <a href="./collaboration">collaboration statement</a> for more details. You are also welcome to befriend me on <a href="./assets/img/Wechat.jpg">Wechat</a> or connect me through <a href="https://www.linkedin.com/in/zhangyihua/" target="_blank" rel="noopener noreferrer">LinkedIn</a>.</p>


          </div>

          <!-- News -->          
          <div class="news">
            <h2>News</h2>
            <div class="table-responsive" style="max-height: 40vw">
              <table class="table table-sm table-borderless">
               
                <tr>
                  <th scope="row">May 16, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> One first-authored paper <a href="https://arxiv.org/pdf/2411.18797" target="_blank" rel="noopener noreferrer">SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?</a> is accepted to ACL 2025 main conference!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 1, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Two papers accepted in ICML‚Äô25!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 16, 2025</th>
                  <td>
                    <img class="emoji" title=":medal_sports:" alt=":medal_sports:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c5.png" height="20" width="20"> Honored to receive the <strong>First Place Award</strong> in the <a href="https://engineering.msu.edu/academics/graduate-studies" target="_blank" rel="noopener noreferrer">2024‚Äì25 Fitch H. Beach Award</a> competition ‚Äî the highest distinction for graduate students at the MSU College of Engineering! I‚Äôll be proudly representing the Computer Science department at the college-wide awards ceremony on April 30. üéìüíö
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 26, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> My co-first-authored paper <a href="https://arxiv.org/abs/2411.16832" target="_blank" rel="noopener noreferrer">Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing</a> is accepted to CVPR 2025&lt;/a&gt;! Congratulations to my summer intern Hanhui!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 22, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> Our paper <a href="https://openreview.net/pdf?id=vRvVVb0NAz" target="_blank" rel="noopener noreferrer">When is Task Vector Provably Effective Model Editing? A Generalization Analysis of Nonlinear Transformers</a> is accepted to <a href="https://aaai.org/Conferences/AAAI-23/aaai23tutorials/" target="_blank" rel="noopener noreferrer"> ICLR 2025 as an <b>Oral Presentation (only 1.8% acceptance rate)</b></a>!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 21, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> I am awarded with the <a href="https://cpal.cc/rising_stars_guidelines/" target="_blank" rel="noopener noreferrer">CPAL Rising Star Award 2025</a> and will give a presentation at Stanford in March 2025.!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 20, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> My new technical post <a href="https://normaluhr.github.io/2025/01/20/deepseek-r1/" target="_blank" rel="noopener noreferrer">From Zero to Reasoning Hero: How DeepSeek-R1 Leverages Reinforcement Learning to Master Complex Reasoning (ÂçÉÂëº‰∏áÂî§ÂßãÂá∫Êù•ÔºöDeepSeek-R1 Â¶Ç‰ΩïÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÂÆûÁé∞Â§çÊùÇÊé®ÁêÜ) </a> is now online! English and Chinese versions both available!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 15, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> My new technical post <a href="https://normaluhr.github.io/2025/01/15/moe-load-balancing/" target="_blank" rel="noopener noreferrer">A Review on the Evolvement of Load Balancing Strategy in MoE LLMs: Pitfalls and Lessons (ÂÖ≥‰∫é MoE Â§ßÊ®°ÂûãË¥üËΩΩÂùáË°°Á≠ñÁï•ÊºîËøõÁöÑÂõûÈ°æÔºöÂùëÁÇπ‰∏éÁªèÈ™åÊïôËÆ≠) </a> is now online! English and Chinese versions both available!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 10, 2025</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> I am awarded with the <a href="https://research.ibm.com/university/awards/fellowships.html" target="_blank" rel="noopener noreferrer">IBM PhD Fellowship 2024-2025</a>!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Dec 15, 2024</th>
                  <td>
                    <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> My new technical post <a href="https://normaluhr.github.io/2024/12/15/unlearning-pitfalls/" target="_blank" rel="noopener noreferrer">Patching the Foundation Models: Pitfalls and Pains in Machine Unlearning (ÁªôÂ§ßÊ®°ÂûãÊâìÊâìË°•‰∏ÅÔºöÊú∫Âô®ÂèçÂ≠¶‰π†ÊñπÊ≥ï‰∏≠ÁöÑÈô∑Èò±‰∏éÁóõÁÇπ) </a> is now online! English and Chinese versions both available!
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

          <!-- Selected papers -->
          <div class="publications">
            <h2>First-Authored Publications</h2>
            
            <h5 class="year">See a full publication list at <a href="https://www.yihua-zhang.com/publications/" target="_blank" rel="noopener noreferrer">here</a>.</h5>
            <br>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">CVPR‚Äô25</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/facelock.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="wang2025edit" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing</div>
          <!-- Author -->
          <div class="author">
          

          Hanhui Wang,¬†<em>Yihua Zhang</em>,¬†Ruizheng Bai,¬†Yue Zhao,¬†Sijia Liu,¬†and¬†Zhengzhong Tu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025</em> 2025
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/pdf/2411.16832" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/taco-group/FaceLock" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent advancements in diffusion models have made generative image editing more accessible than ever. While these developments allow users to generate creative edits with ease, they also raise significant ethical concerns, particularly regarding malicious edits to human portraits that threaten individuals‚Äô privacy and identity security. Existing general-purpose image protection methods primarily focus on generating adversarial perturbations to nullify edit effects. However, these approaches often exhibit instability to protect against diverse editing requests. In this work, we introduce a novel perspective to personal human portrait protection against malicious editing. Unlike traditional methods aiming to prevent edits from taking effect, our method, FACELOCK, optimizes adversarial perturbations to ensure that original biometric information‚Äîsuch as facial features‚Äîis either destroyed or substantially altered post-editing, rendering the subject in the edited output biometrically unrecognizable. Our approach innovatively integrates facial recognition and visual perception factors into the perturbation optimization process, ensuring robust protection against a variety of editing attempts. Besides, we shed light on several critical issues with commonly used evaluation metrics in image editing and reveal cheating methods by which they can be easily manipulated, leading to deceptive assessments of protection. Through extensive experiments, we demonstrate that FACELOCK significantly outperforms all baselines in defense performance against a wide range of malicious edits. Moreover, our method also exhibits strong robustness against purification techniques. Comprehensive ablation studies confirm the stability and broad applicability of our method across diverse diffusion-based editing algorithms. Our work not only advances the state-of-the-art in biometric defense but also sets the foundation for more secure and privacy-preserving practices in image editing. The code is publicly available at: https://github.com/taco-group/FaceLock.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2025edit</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Hanhui and Zhang, Yihua and Bai, Ruizheng and Zhao, Yue and Liu, Sijia and Tu, Zhengzhong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">NeurIPS‚Äô24 D&amp;B</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/unlearn_canvas.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2024unlearncanvas" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang</em>,¬†Chongyu Fan,¬†Yimeng Zhang,¬†Yuguang Yao,¬†Jinghan Jia,¬†Jiancheng Liu,¬†Gaoyuan Zhang,¬†Gaowen Liu,¬†Ramana Kompella,¬†Xiaoming Liu, and
            <span class="more-authors" title="click to view 1 more author" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '1 more author' ? 'Sijia Liu' : '1 more author';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '12');
                ">1 more author</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-eighth Conference on Neural Information Processing Systems</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/pdf/2402.11846" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/UnlearnCanvas" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://www.youtube.com/watch?v=lC_R_b9ZiH8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
            <a href="https://unlearn-canvas.netlify.app/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The technological advancements in diffusion models (DMs) have demonstrated unprecedented capabilities in text-to-image generation and are widely used in diverse applications. However, they have also raised significant societal concerns, such as the generation of harmful content and copyright disputes. Machine unlearning (MU) has emerged as a promising solution, capable of removing undesired generative capabilities from DMs. However, existing MU evaluation systems present several key challenges that can result in incomplete and inaccurate assessments. To address these issues, we propose UNLEARNCANVAS, a comprehensive highresolution stylized image dataset that facilitates the evaluation of the unlearning of artistic styles and associated objects. This dataset enables the establishment of a standardized, automated evaluation framework with 7 quantitative metrics assessing various aspects of the unlearning performance for DMs. Through extensive experiments, we benchmark 9 state-of-the-art MU methods for DMs, revealing novel insights into their strengths, weaknesses, and underlying mechanisms. Additionally, we explore challenging unlearning scenarios for DMs to evaluate worst-case performance against adversarial prompts, the unlearning of finer-scale concepts, and sequential unlearning. We hope that this study can pave the way for developing more effective, accurate, and robust DM unlearning methods, ensuring safer and more ethical applications of DMs in the future.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2024unlearncanvas</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://www.youtube.com/watch?v=lC_R_b9ZiH8}</span><span class="p">,</span>
  <span class="na">dataset</span> <span class="p">=</span> <span class="s">{https://huggingface.co/datasets/OPTML-Group/UnlearnCanvas}</span><span class="p">,</span>
  <span class="na">benchmark</span> <span class="p">=</span> <span class="s">{https://huggingface.co/spaces/OPTML-Group/UnlearnCanvas-Benchmark}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yihua and Fan, Chongyu and Zhang, Yimeng and Yao, Yuguang and Jia, Jinghan and Liu, Jiancheng and Zhang, Gaoyuan and Liu, Gaowen and Kompella, Ramana and Liu, Xiaoming and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-eighth Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">ICML‚Äô24</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/zo_bench.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2024revisiting" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark </div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang</em>,¬†Pingzhi Li,¬†Junyuan Hong,¬†Jiaxiang Li,¬†Yimeng Zhang,¬†Wenqing Zheng,¬†Pin-Yu Chen,¬†Jason D. Lee,¬†Wotao Yin,¬†Mingyi Hong, and
            <span class="more-authors" title="click to view 3 more authors" onclick="
                  var element = $(this);
                  element.attr('title', '');
                  var more_authors_text = element.text() == '3 more authors' ? 'Zhangyang Wang, Sijia Liu, Tianlong Chen' : '3 more authors';
                  var cursorPosition = 0;
                  var textAdder = setInterval(function(){
                    element.text(more_authors_text.substring(0, cursorPosition + 1));
                    if (++cursorPosition == more_authors_text.length){
                      clearInterval(textAdder);
                    }
                }, '12');
                ">3 more authors</span>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In arXiv preprint arXiv:2402.11592</em> Feb 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/pdf/2402.11592" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/ZO-Bench/ZO-LLM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/zo_bench.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the evolving landscape of natural language processing (NLP), fine-tuning pre-trained Large Language Models (LLMs) with first-order (FO) optimizers like SGD and Adam has become standard. Yet, as LLMs grow in size, the substantial memory overhead from back-propagation (BP) for FO gradient computation presents a significant challenge. Addressing this issue is crucial, especially for applications like on-device training where memory efficiency is paramount. This paper proposes a shift towards BP-free, zeroth-order (ZO) optimization as a solution for reducing memory costs during LLM fine-tuning, building on the initial concept introduced by Malladi et al. (2023). Unlike traditional ZO-SGD methods, our work expands the exploration to a wider array of ZO optimization techniques, through a comprehensive, firstof-its-kind benchmarking study across five LLM families (Roberta, OPT, LLaMA, Vicuna, Mistral), three task complexities, and five fine-tuning schemes. Our study unveils previously overlooked optimization principles, highlighting the importance of task alignment, the role of the forward gradient method, and the balance between algorithm complexity and fine-tuning performance. We further introduce novel enhancements to ZO optimization, including block-wise descent, hybrid training, and gradient sparsity. Our study offers a promising direction for achieving further memory-efficient LLM fine-tuning. Codes to reproduce all our experiments are at https://github.com/ZO-Bench/ZO-LLM.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2024revisiting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark }</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yihua and Li, Pingzhi and Hong, Junyuan and Li, Jiaxiang and Zhang, Yimeng and Zheng, Wenqing and Chen, Pin-Yu and Lee, Jason D. and Yin, Wotao and Hong, Mingyi and Wang, Zhangyang and Liu, Sijia and Chen, Tianlong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2402.11592}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">IEEE SPM</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/blo_survey.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2023introduction" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang</em>,¬†Prashant Khanduri,¬†Ioannis Tsaknakis,¬†Yuguang Yao,¬†Mingyi Hong,¬†and¬†Sijia Liu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In arxiv 2308.00788</em> Aug 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/abs/2308.00788" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="./" class="btn btn-sm z-depth-0" role="button">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recently, bi-level optimization (BLO) has taken center stage in some very exciting developments in the area of signal processing (SP) and machine learning (ML). Roughly speaking, BLO is a classical optimization problem that involves two levels of hierarchy (i.e., upper and lower levels), wherein obtaining the solution to the upper-level problem requires solving the lower-level one. BLO has become popular largely because it is powerful in modeling problems in SP and ML, among others, that involve optimizing nested objective functions. Prominent applications of BLO range from resource allocation for wireless systems to adversarial machine learning. In this work, we focus on a class of tractable BLO problems that often appear in SP and ML applications. We provide an overview of some basic concepts of this class of BLO problems, such as their optimality conditions, standard algorithms (including their optimization principles and practical implementations), as well as how they can be leveraged to obtain state-of-the-art results for a number of key SP and ML applications. Further, we discuss some recent advances in BLO theory, its implications for applications, and point out some limitations of the state-of-the-art that require significant future research efforts. Overall, we hope that this article can serve to accelerate the adoption of BLO as a generic tool to model, analyze, and innovate on a wide array of emerging SP and ML applications.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2023introduction</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yihua and Khanduri, Prashant and Tsaknakis, Ioannis and Yao, Yuguang and Hong, Mingyi and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">NeurIPS‚Äô23</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/dp_flm.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2023selectivity" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang</em>,¬†Yimeng Zhang,¬†Aochuan Chen,¬†Jinghan Jia,¬†Jiancheng Liu,¬†Gaowen Liu,¬†Mingyi Hong,¬†Shiyu Chang,¬†and¬†Sijia Liu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-seventh Conference on Neural Information Processing Systems</em> Aug 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/abs/2310.08782" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/DP4TL" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/dp4tl.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
            <a href="https://drive.google.com/file/d/1Xa2XRa1McljGYUwTao4TN8did4zwUUHr/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
            <a href="https://pruning.netlify.app" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Website</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Massive data is often considered essential for deep learning applications, but it also incurs significant computational and infrastructural costs. Therefore, dataset pruning (DP) has emerged as an effective way to improve data efficiency by identifying and removing redundant training samples without sacrificing performance. In this work, we aim to address the problem of DP for transfer learning, i.e., how to prune a source dataset for improved pretraining efficiency and lossless finetuning accuracy on downstream target tasks. To our best knowledge, the problem of DP for transfer learning remains open, as previous studies have primarily addressed DP and transfer learning as separate problems. By contrast, we establish a unified viewpoint to integrate DP with transfer learning and find that existing DP methods are not suitable for the transfer learning paradigm. We then propose two new DP methods, label mapping and feature mapping, for supervised and self-supervised pretraining settings respectively, by revisiting the DP problem through the lens of source-target domain mapping. Furthermore, we demonstrate the effectiveness of our approach on numerous transfer learning tasks. We show that source data classes can be pruned by up to 40% without sacrificing the downstream performance, resulting in a significant 2¬†5 times speed-up during the pretraining stage. Besides, our proposal exhibits broad applicability and can improve other computationally intensive transfer learning techniques, such as adversarial pretraining.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2023selectivity</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yihua and Zhang, Yimeng and Chen, Aochuan and Jia, Jinghan and Liu, Jiancheng and Liu, Gaowen and Hong, Mingyi and Chang, Shiyu and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-seventh Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">post</span> <span class="p">=</span> <span class="s">{https://pruning.netlify.app/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">ICCV‚Äô23</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/moe.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2023robust" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Robust Mixture-of-Expert Training for Convolutional Neural Networks</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang</em>,¬†Ruisi Cai,¬†Tianlong Chen,¬†Guanhua Zhang,¬†Huan Zhang,¬†Pin-Yu Chen,¬†Shiyu Chang,¬†Zhangyang Wang,¬†and¬†Sijia Liu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em> Oct 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/abs/2308.10110v1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/Robust-MoE-CNN" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/advmoe.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
            <a href="https://drive.google.com/file/d/1k_tWNdOf56cjnEfKR6d-ZIHkBVDC0CQ9/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ¬† 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2023robust</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust Mixture-of-Expert Training for Convolutional Neural Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yihua and Cai, Ruisi and Chen, Tianlong and Zhang, Guanhua and Zhang, Huan and Chen, Pin-Yu and Chang, Shiyu and Wang, Zhangyang and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">ICLR‚Äô23</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/bloc_irm.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2023what" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">What Is Missing in IRM Training and Evaluation? Challenges and Solutions</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang</em>,¬†Pranay Sharma,¬†Parikshit Ram,¬†Mingyi Hong,¬†Kush Varshney,¬†and¬†Sijia Liu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Eleventh International Conference on Learning Representations</em> Oct 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://openreview.net/forum?id=MjsDeTcDEy&amp;referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2023%2FConference%2FAuthors%23your-submissions)" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/BLOC-IRM" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/bloc_irm.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Invariant risk minimization (IRM) has received increasing attention as a way to acquire environment-agnostic data representations and predictions, and as a principled solution for preventing spurious correlations from being learned and for improving models‚Äô out-of-distribution generalization. Yet, recent works have found that the optimality of the originally-proposed IRM optimization (IRM) may be compromised in practice or could be impossible to achieve in some scenarios. Therefore, a series of advanced IRM algorithms have been developed that show practical improvement over IRM. In this work, we revisit these recent IRM advancements, and identify and resolve three practical limitations in IRM training and evaluation. First, we find that the effect of batch size during training has been chronically overlooked in previous studies, leaving room for further improvement. We propose small-batch training and highlight the improvements over a set of large-batch optimization techniques. Second, we find that improper selection of evaluation environments could give a false sense of invariance for IRM. To alleviate this effect, we leverage diversified test-time environments to precisely characterize the invariance of IRM when applied in practice. Third, we revisit (Ahuja et al. (2020))‚Äôs proposal to convert IRM into an ensemble game and identify a limitation when a single invariant predictor is desired instead of an ensemble of individual predictors. We propose a new IRM variant to address this limitation based on a novel viewpoint of ensemble IRM games as consensus-constrained bi-level optimization. Lastly, we conduct extensive experiments (covering 7 existing IRM variants and 7 datasets) to justify the practical significance of revisiting IRM training and evaluation in a principled manner.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2023what</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{What Is Missing in IRM Training and Evaluation? Challenges and Solutions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yihua and Sharma, Pranay and Ram, Parikshit and Hong, Mingyi and Varshney, Kush and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Eleventh International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">NeurIPS‚Äô22</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/bip.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2022advancing" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Advancing Model Pruning via Bi-level Optimization</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang*</em>,¬†Yuguang Yao*,¬†Parikshit Ram,¬†Pu Zhao,¬†Tianlong Chen,¬†Mingyi Hong,¬†Yanzhi Wang,¬†and¬†Sijia Liu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-sixth Conference on Neural Information Processing Systems</em> Oct 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/pdf/2210.04092.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/BiP" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/bip.jpg" class="btn btn-sm z-depth-0" role="button">Poster</a>
            <a href="https://drive.google.com/file/d/1YSQUaLoeG45KjCdINmsaFTo6kQIM6Jwk/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
            <a href="https://youtu.be/eeKITiOOTaE" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The deployment constraints in practical applications necessitate the pruning of large-scale deep learning models, i.e., promoting their weight sparsity. As illustrated by the Lottery Ticket Hypothesis (LTH), pruning also has the potential of improving their generalization ability. At the core of LTH, iterative magnitude pruning (IMP) is the predominant pruning method to successfully find ‚Äòwinning tickets‚Äô. Yet, the computation cost of IMP grows prohibitively as the targeted pruning ratio increases. To reduce the computation overhead, various efficient ‚Äòone-shot‚Äô pruning methods have been developed, but these schemes are usually unable to find winning tickets as good as IMP. This raises the question of how to close the gap between pruning accuracy and pruning efficiency? To tackle it, we pursue the algorithmic advancement of model pruning. Specifically, we formulate the pruning problem from a fresh and novel viewpoint, bi-level optimization (BLO). We show that the BLO interpretation provides a technically-grounded optimization base for an efficient implementation of the pruning-retraining learning paradigm used in IMP. We also show that the proposed bi-level optimization-oriented pruning method (termed BiP) is a special class of BLO problems with a bi-linear problem structure. By leveraging such bi-linearity, we theoretically show that BiP can be solved as easily as first-order optimization, thus inheriting the computation efficiency. Through extensive experiments on both structured and unstructured pruning with 5 model architectures and 4 data sets, we demonstrate that BiP can find better winning tickets than IMP in most cases, and is computationally as efficient as the one-shot pruning schemes, demonstrating 2-7\times speedup over IMP for the same level of model accuracy and sparsity.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2022advancing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Advancing Model Pruning via Bi-level Optimization}</span><span class="p">,</span>
  <span class="na">video</span> <span class="p">=</span> <span class="s">{https://youtu.be/eeKITiOOTaE}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Yihua and Yao*, Yuguang and Ram, Parikshit and Zhao, Pu and Chen, Tianlong and Hong, Mingyi and Wang, Yanzhi and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-sixth Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">NeurIPS‚Äô22</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/fair.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2022fairness" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Fairness Reprogramming</div>
          <!-- Author -->
          <div class="author">
          

          Guanhua Zhang*,¬†<em>Yihua Zhang*</em>,¬†Yang Zhang,¬†Wenqi Fan,¬†Qing Li,¬†Sijia Liu,¬†and¬†Shiyu Chang</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirty-sixth Conference on Neural Information Processing Systems</em> Oct 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/pdf/2209.10222.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/Fairness-Reprogramming" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/fairness_reprogramming.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Despite a surge of recent advances in promoting machine Learning (ML) fairness, the existing mainstream approaches mostly require training or finetuning the entire weights of the neural network to meet the fairness criteria. However, this is often infeasible in practice for those large-scale trained models due to large computational and storage costs, low data efficiency, and model privacy issues. In this paper, we propose a new generic fairness learning paradigm, called FairReprogram, which incorporates the model reprogramming technique. Specifically, FairReprogram considers the neural model fixed, and instead appends to the input a set of perturbations, called the fairness trigger, which is tuned towards the fairness criteria under a min-max formulation. We further introduce an information-theoretic framework that explains why and under what conditions fairness goals can be achieved using the fairness trigger. We show both theoretically and empirically that the fairness trigger can effectively obscure demographic biases in the output prediction of fixed ML models by providing false demographic information that hinders the model from utilizing the correct demographic information to make the prediction. Extensive experiments on both NLP and CV datasets demonstrate that our method can achieve better fairness improvements than retraining-based methods with far less training cost and data dependency under two widely-used fairness criteria.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2022fairness</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fairness Reprogramming}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Guanhua and Zhang*, Yihua and Zhang, Yang and Fan, Wenqi and Li, Qing and Liu, Sijia and Chang, Shiyu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Thirty-sixth Conference on Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">ICML‚Äô22</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/fastbat.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="zhang2022revisiting" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization</div>
          <!-- Author -->
          <div class="author">
          

          <em>Yihua Zhang*</em>,¬†Guanhua Zhang*,¬†Prashant Khanduri,¬†Mingyi Hong,¬†Shiyu Chang,¬†and¬†Sijia Liu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 39th International Conference on Machine Learning</em> Oct 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://proceedings.mlr.press/v162/zhang22ak/zhang22ak.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/OPTML-Group/Fast-BAT" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/fast_bat.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
            <a href="https://drive.google.com/file/d/13uI2Uzl_yLNdx2o1QqjGiQWFmL8RLaCn/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
            <a href="https://slideslive.com/38983942" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Adversarial training (AT) is a widely recognized defense mechanism to gain the robustness of deep neural networks against adversarial attacks. It is built on min-max optimization (MMO), where the minimizer (i.e., defender) seeks a robust model to minimize the worst-case training loss in the presence of adversarial examples crafted by the maximizer (i.e., attacker). However, the conventional MMO method makes AT hard to scale. Thus, Fast-AT and other recent algorithms attempt to simplify MMO by replacing its maximization step with the single gradient sign-based attack generation step. Although easy to implement, FAST-AT lacks theoretical guarantees, and its empirical performance is unsatisfactory due to the issue of robust catastrophic overfitting when training with strong adversaries. In this paper, we advance Fast-AT from the fresh perspective of bi-level optimization (BLO). We first show that the commonly-used Fast-AT is equivalent to using a stochastic gradient algorithm to solve a linearized BLO problem involving a sign operation. However, the discrete nature of the sign operation makes it difficult to understand the algorithm performance. Inspired by BLO, we design and analyze a new set of robust training algorithms termed Fast Bi-level AT (Fast-BAT), which effectively defends sign-based projected gradient descent (PGD) attacks without using any gradient sign method or explicit robust regularization. In practice, we show that our method yields substantial robustness improvements over multiple baselines across multiple models and datasets.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2022revisiting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Yihua and Zhang*, Guanhua and Khanduri, Prashant and Hong, Mingyi and Chang, Shiyu and Liu, Sijia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 39th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{26693--26712}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
  <div class="row">

    <div class="col-sm-3 abbr">
      
            <abbr class="badge">CVPR‚Äô22</abbr>
        
      
      
        <img src="/changsheng-wang/assets/img/publication_preview/sparse_trojan.png" class="teaser img-fluid z-depth-1">
      
    </div>

        <!-- Entry bib key -->
        <div id="chen2022quarantine" class="col-sm-9">
        
          <!-- Title -->
          <div class="title">Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free</div>
          <!-- Author -->
          <div class="author">
          

          Tianlong Chen*,¬†Zhenyu Zhang*,¬†<em>Yihua Zhang*</em>,¬†Shiyu Chang,¬†Sijia Liu,¬†and¬†Zhangyang Wang</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> Oct 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          <!--
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> -->
            <a href="https://arxiv.org/pdf/2205.11819.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a>
            <a href="https://github.com/VITA-Group/Backdoor-LTH" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="/changsheng-wang/assets/posters/trojan_lth.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Trojan attacks threaten deep neural networks (DNNs) by poisoning them to behave normally on most samples, yet to produce manipulated results for inputs attached with a particular trigger. Several works attempt to detect whether a given DNN has been injected with a specific trigger during the training. In a parallel line of research, the lottery ticket hypothesis reveals the existence of sparse subnetworks which are capable of reaching competitive performance as the dense network after independent training. Connecting these two dots, we investigate the problem of Trojan DNN detection from the brand new lens of sparsity, even when no clean training data is available. Our crucial observation is that the Trojan features are significantly more stable to network pruning than benign features. Leveraging that, we propose a novel Trojan network detection regime: first locating a "winning Trojan lottery ticket" which preserves nearly full Trojan information yet only chance-level performance on clean inputs; then recovering the trigger embedded in this already isolated subnetwork. Extensive experiments on various datasets, i.e., CIFAR-10, CIFAR-100, and ImageNet, with different network architectures, i.e., VGG-16, ResNet-18, ResNet-20s, and DenseNet-100 demonstrate the effectiveness of our proposal.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2022quarantine</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen*, Tianlong and Zhang*, Zhenyu and Zhang*, Yihua and Chang, Shiyu and Liu, Sijia and Wang, Zhangyang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{598--609}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%7A%68%61%6E%31%39%30%38@%6D%73%75.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=ui-pcWgAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/normaluhr" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/zhangyihua" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/zyh2022" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            <a href="./assets/img/Wechat.jpg" title="WeChat"><i class="fa fa-wechat"></i></a>
            

            </div>

            <div class="contact-note">
              
            </div>
            
          </div>
        </article>

</div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <center>
        <div id="clustrmaps-widget" style="width:10%">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=zP5RUg_lbda1vEJcVf6Y2wExCgt16XQuzyNJY2frl-I"></script>
        </div>
      <div class="container">
        ¬© Copyright 2025 Yihua  Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>.
Last updated: July 12, 2025.
      </div>
      </center>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/changsheng-wang/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Enable Tooltips -->
  <script type="text/javascript">
  $(function () {$('[data-toggle="tooltip"]').tooltip()})
  </script>
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/changsheng-wang/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/changsheng-wang/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };

    window.MathJax = {
    tex: {
      tags: 'ams'
      inlineMath: [['$', '$'], ['\\(', '\\)'], ['!!', '!!']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <!-- <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$']]
        packages: ['base', 'newcommand', 'configMacros']
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script> -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

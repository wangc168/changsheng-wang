<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>[NeurIPS22] Advancing Model Pruning via Bi-level Optimization | Yihua Zhang</title>
    <meta name="author" content="Yihua  Zhang" />
    <meta name="description" content="Don't waste your life. Don't waste it.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>☯️</text></svg>">
    
    <link rel="stylesheet" href="/changsheng-wang/assets/css/main.css">
    <link rel="canonical" href="https://changsheng-wang.github.io/changsheng-wang/blog/2022/bip-neurips22/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/changsheng-wang/assets/js/theme.js"></script>
    <script src="/changsheng-wang/assets/js/dark_mode.js"></script>
    

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#155799">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/changsheng-wang/assets/css/paper.css?v=">
  </head>

  <!-- Body -->
  <body class=" sticky-bottom-footer">

    <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/changsheng-wang/">Yihua Zhang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/changsheng-wang/blog/">Posts<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/collaboration/">Collaboration</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/changsheng-wang/photos/">Photos</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

    <header class="page-header" role="banner">
      <h1 class="project-name font-size:250%" style="color:white">[NeurIPS22] Advancing Model Pruning via Bi-level Optimization</h1>
      <br>
      <h2 class="project-tagline" style="color:white">
<a style="color: #dfebf7" href="https://www.yihua-zhang.com/" target="_blank" rel="noopener noreferrer">Yihua Zhang</a><sup>[1]</sup>*, <a style="color: #dfebf7" href="https://www.cse.msu.edu/~yaoyugua/" target="_blank" rel="noopener noreferrer">Yuguang Yao</a><sup>[1]</sup>*, <a style="color: #dfebf7" href="https://rithram.github.io/" target="_blank" rel="noopener noreferrer">Parikshit Ram</a><sup>[2]</sup>, <a style="color: #dfebf7" href="https://puzhao.info/" target="_blank" rel="noopener noreferrer">Zhao Pu</a><sup>[3]</sup>, <a style="color: #dfebf7" href="https://tianlong-chen.github.io/about/" target="_blank" rel="noopener noreferrer">Tianlong Chen</a><sup>[4]</sup>, <a style="color: #dfebf7" href="https://people.ece.umn.edu/~mhong/mingyi.html" target="_blank" rel="noopener noreferrer">Mingyi Hong</a><sup>[5]</sup>, <a style="color: #dfebf7" href="https://web.northeastern.edu/yanzhiwang/" target="_blank" rel="noopener noreferrer">Yanzhi Wang</a><sup>[3]</sup>, <a style="color: #dfebf7" href="https://lsjxjtu.github.io/" target="_blank" rel="noopener noreferrer">Sijia Liu</a><sup>[1,2]</sup>
</h2>
      <h2 class="project-tagline" style="color:white">
<sup>[1]</sup>Michigan State University, <sup>[2]</sup>IBM Research, <sup>[3]</sup>Northeastern University, <sup>[4]</sup>University of Texas at Austin, <sup>[5]</sup>University of Minnesota, Twin City</h2>
      
      <a href="https://arxiv.org/pdf/2210.04092.pdf" class="btn" target="_blank" rel="noopener noreferrer">Paper</a>
      
      
      <a href="https://github.com/OPTML-Group/BiP" class="btn" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      <a href="https://www.yihua-zhang.com/assets/posters/bip.jpg" class="btn" target="_blank" rel="noopener noreferrer">Poster</a>
      
      
      
      
      
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <h4 id="dilemma-in-model-pruning-effective-or-efficient">Dilemma in Model Pruning: Effective or Efficient?</h4>

<p>Among the many powerful pruning methods, Iterative Magnitude Pruning (IMP) is one of the most significant and popular methods, which prunes the model in an iterative manner and can reach an extremely sparse level without any performance loss. However, it often consumes much more than training a dense model from scratch. In contrast, efficient one-shot pruning methods can not deliver a high-quality sparse subnetwork, as shown in Figure 1.
Therefore, existing pruning methods have reached a dilemma over choosing between the effective method and the efficient method.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/dilemma-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/dilemma-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/dilemma-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/dilemma.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Dilemma in Pruning" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 1. The dilemma in model pruning: Powerful pruning methods (e.g., IMP) suffer from high computational overhead.
</div>

<hr>

<center>
<b>
How to advance the optimization foundation of model pruning to achieve high accuracy and pruning efficiency?
</b>
<br>
</center>

<hr>

<h4 id="model-pruning-as-a-bi-level-optimization-problem">Model Pruning as a Bi-level Optimization Problem</h4>

<p>We start our research by revisiting the model pruning problem and reformulating it to a bi-level optimization (BLO) problem:</p>

\[\min_{\mathbf{m} \in \mathcal{S}} \ell(\mathbf{m} \odot \boldsymbol\theta^{\ast}(\mathbf{m})) \quad \quad \text{subject to} \,\,\, \boldsymbol\theta^{\ast}(\mathbf{m}) = \text{argmin}_{\boldsymbol\theta \in \mathbb{R}^n}\, \ell(\mathbf{m} \odot \boldsymbol\theta + \frac{\gamma}{2}\|\boldsymbol\theta\|_2^2),\]

<p>where the upper-level problem optimizes the pruning mask for the model and the lower-level retrains the model with the fixed mask. The benefits from this bi-level formulation are two-folded.</p>

<ul>
  <li>
    <p>First, we have the flexibility to use the mismatched pruning and retraining objectives.</p>
  </li>
  <li>
    <p>Second, the bi-level optimization enables us to explicitly optimize the coupling between the retrained model weights and the pruning mask through the implicit gradient (IG)-based optimization routine.</p>
  </li>
</ul>

<h4 id="optimization-foundation-of-bip">Optimization Foundation of BIP</h4>

<p>BLO is different from other optimization problems, as the gradient descent of the upper-level variable will involve the calculation of the implicit gradient (IG)：</p>

\[\frac{d\ell(\mathbf{m}\odot\boldsymbol\theta^\ast(\mathbf{m}))}{d\mathbf{m}} = \nabla_{\mathbf{m}}\ell(\mathbf{m}\odot\boldsymbol\theta^\ast(\mathbf{m})) + \frac{d{\boldsymbol\theta^\ast(\mathbf{m})}^\top}{d\mathbf{m}} \nabla_{\boldsymbol\theta}\ell(\mathbf{m}\odot\boldsymbol\theta^\ast(\mathbf{m})).\]

<p>The IG challenge is a fingerprint of the BLO solver and derives from the implicit function theory. It refers to the gradient of the lower-level solution w.r.t. the upper-level variable and in most cases is very difficult to calculate. The main reason is it usually involves the second-order derivative and matrix inversion:</p>

\[\frac{d{\boldsymbol\theta^\ast(\mathbf{m})}^\top}{d\mathbf{m}} = -\nabla^2_{\mathbf{m}\boldsymbol\theta}\ell(\mathbf{m}\odot\boldsymbol\theta^\ast)[\nabla^2_{\boldsymbol\theta}\ell(\mathbf{m}\odot\boldsymbol\theta^\ast) + \gamma \mathbf{I}]^{-1}.\]

<p>Very luckily, in the model pruning scenario, the upper- and lower-level variables are always combined as bi-linear variables. We can thus leverage this bi-linear property and derive a closed-form IG solution, which only requires the first-order derivative:</p>

\[\frac{d{\boldsymbol\theta^\ast(\mathbf{m})}^\top}{d\mathbf{m}} = -\frac{1}{\gamma} \text{diag}(\nabla_{\mathbf{z}}\ell(\mathbf{z})|_{\mathbf{z} = \mathbf{m} \odot \boldsymbol\theta^\ast}).\]

<p>This also makes our later proposed bi-level pruning algorithm a purely first-order method.</p>

<hr>

<h4 id="bip-bi-level-optimization-based-pruning">BiP: Bi-level Optimization-based Pruning</h4>

<p>We propose our bi-level pruning algorithm (BiP). We adopt the alternating optimization procedure by updating the upper- and lower-variable in turn.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/algorithm-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/algorithm-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/algorithm-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/algorithm.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="BiP algorithm overview" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 2. The pseudo-code for Bi-level Pruning (BiP) Algorithm.
</div>

<h5 id="more-details-of-bip">More details of BiP</h5>

<p>We show the illustration of the BiP algorithm in Figure 3 below. We start with a pretrained model and some mask initialization. For the lower level, we use stochastic gradient descent to update the model parameter with the fixed mask.
For the upper level, as the mask is supposed to contain either 0 or 1, representing whether a parameter should be removed or retained, we first relax the “binary” masking “variables” to “continuous” masking “scores”, which can be updated with auto-differentiation in most of the deep learning algorithms. In the forward path, we project the scores onto the discrete constraint using hard thresholding, where the top k elements are set to 1s and the others to 0s. Thus, we summarize our upper-level problem as stochastic projected gradient descent, in short SPGD.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/bip_overview-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/bip_overview-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/bip_overview-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/bip_overview.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="BiP algorithm visualization" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 3. An illustration of the proposed BiP algorithm.
</div>

<h5 id="comparison-to-imp-and-omp">Comparison to IMP and OMP</h5>

<p>We also show the illustration of the iterative magnitude pruning (IMP) and one-shot magnitude pruning (OMP) below for comparison.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/imp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/imp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/imp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/imp.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="BiP algorithm overview" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 4. Pruning pipeline visualization of IMP.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/omp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/omp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/omp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/omp.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="BiP algorithm overview" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 5. Pruning pipeline visualization of OMP.
</div>

<hr>

<h4 id="experiment-results">Experiment results</h4>

<h5 id="bip-identifies-high-accuracy-subnetworks-in-unstructured-pruning">BIP identifies high-accuracy subnetworks in unstructured pruning</h5>

<p>In Figure 6 below, we show the unstructured pruning trajectory (given by test accuracy vs. pruning ratio) of BIP and baseline methods in 8 model-dataset setups. BiP outperforms its baselines in nearly all the settings and also finds the sparsest winning tickets nearly every time. For some settings like CIFAR-10 with model VGG-16, BiP is even capable of finding winning tickets with a pruning ratio over 90%</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_unstructured_pruning-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_unstructured_pruning-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_unstructured_pruning-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/exp_unstructured_pruning.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Unstructured pruning result." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 6. Unstructured pruning trajectory given by test accuracy (%) vs. sparsity (%) on various (dataset, model) pairs. The performance of the dense model and the best winning ticket is marked using dashed lines in each plot. The solid line and shaded area of each pruning method represent the mean and variance of test accuracies over 3 trials.
</div>

<h5 id="bip-identifies-high-accuracy-subnetworks-in-structured-pruning">BIP identifies high-accuracy subnetworks in structured pruning</h5>

<p>A similar phenomenon can be observed in the structured pruning setting as well.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_structured_pruning-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_structured_pruning-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_structured_pruning-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/exp_structured_pruning.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Structured pruning result." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 7. Filter-wise pruning trajectory given by test accuracy (%) vs. sparsity (%). Other settings strictly follow Figure 3.
</div>

<h5 id="bip-achieves-high-pruning-efficiency">BiP achieves high pruning efficiency.</h5>

<p>Next, we show the high efficiency of BiP compared to the state-of-the-art IMP method <a href="#refer-anchor-1">[1]</a>. As we have longed for, BiP consumes sparsity-agnostic time consumptions just like the one-shot pruning methods and can be 3~7 times faster than IMP.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_time-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_time-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/exp_time-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/exp_time.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Structured pruning result." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 8. Time consumption comparison on (CIFAR-10, ResNet-18) with different pruning ratios p.
</div>

<h5 id="bip-requires-no-rewinding">BiP requires no rewinding.</h5>

<p>Another advantage of BIP is that it insensitive to model rewinding to
find matching subnetworks. Recall that rewinding is a strategy used in Lottery Ticket Hypothesis <a href="#refer-anchor-2">[2]</a> to determine what model initialization should be used for retraining a pruned model. In Figure 9, we show the test accuracy of the BIP-pruned model when it is retrained at different rewinding epochs under various datasets and model architectures. As we can see, a carefully-tuned rewinding scheme does not lead to a significant improvement over BIP without retraining. This suggests that the subnetworks found by BIP are already of high quality and do not require any rewinding operation.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/no_rewinding-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/no_rewinding-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/changsheng-wang/assets/img/posts/bip_nips22/no_rewinding-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/changsheng-wang/assets/img/posts/bip_nips22/no_rewinding.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="BiP requires no rewinding." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 9. The sensitivity of BIP to rewinding epoch numbers on different datasets and model architectures. "N/A" in the x-axis indicates BIP without retraining.
</div>

<hr>

<h4 id="citation">Citation</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td>
<td class="rouge-code"><pre>@inproceedings{zhang2022advancing,
  title = {Advancing Model Pruning via Bi-level Optimization},
  author = {Zhang, Yihua and Yao, Yuguang and Ram, Parikshit and Zhao, Pu and Chen, Tianlong and Hong, Mingyi and Wang, Yanzhi and Liu, Sijia},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2022}
}
</pre></td>
</tr></tbody></table></code></pre></div></div>
<hr>

<h4 id="reference">Reference</h4>

<div id="refer-anchor-1"></div>
<p>[1] Xiaolong Ma et al. “Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?” NeurIPS 2021.</p>

<div id="refer-anchor-2"></div>
<p>[2] Jonathan Frankle et al. “The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks.” ICLR 2019.</p>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <center>
        <div id="clustrmaps-widget" style="width:10%">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=zP5RUg_lbda1vEJcVf6Y2wExCgt16XQuzyNJY2frl-I"></script>
        </div>
      <div class="container">
        © Copyright 2025 Yihua  Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>.
Last updated: July 12, 2025.
      </div>
      </center>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/changsheng-wang/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Enable Tooltips -->
  <script type="text/javascript">
  $(function () {$('[data-toggle="tooltip"]').tooltip()})
  </script>
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/changsheng-wang/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/changsheng-wang/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };

    window.MathJax = {
    tex: {
      tags: 'ams'
      inlineMath: [['$', '$'], ['\\(', '\\)'], ['!!', '!!']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <!-- <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$']]
        packages: ['base', 'newcommand', 'configMacros']
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script> -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

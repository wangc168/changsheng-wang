<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Research | Yihua Zhang</title>
    <meta name="author" content="Yihua  Zhang" />
    <meta name="description" content="Don't waste your life. Don't waste it.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>☯️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/research/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class=" sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Yihua Zhang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blogs -->
              <li class="nav-item">
                <a class="nav-link" href="https://normaluhr.github.io" target="_blank" rel="noopener noreferrer noopener noreferrer">Blogs</a>
              </li>

              <!-- CV -->
              <li class="nav-item">
                <a class="nav-link" href="./CV_Yihua_Zhang.pdf" target="_blank" rel="noopener noreferrer">CV</a>
              </li>
              
              <!-- Blog -->
              <!-- Uncomment below to use in-site blogs -->
              <!--  -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/blog/">Posts</a>
              </li> -->
              <!-- -->

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/collaboration/">Collaboration</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/photos/">Photos</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <article>
            <h1 id="research-statement">Research Statement</h1>

<p>As artificial intelligence (AI) systems move from the laboratory into the real world, a paramount requirement is to develop algorithms that are robust, fair, and interpretable prior to deployment. Moreover, only scalable ML algorithms can better apply to the increasingly complex datasets, models, and tasks. Thus, my research focuses on the <strong>trustworthy</strong> and <strong>scalable</strong> ML algorithms. In general my research scope spans the areas of machine learning (ML)/deep learning (DL), optimization theory, computer vision, and security. These research topics provide a solid foundation for my current and future research: <em>Making AI system safe and scalable.</em> My research on these two goals are intervened and can be summarized as the following two perspectives:</p>

<p><img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> <strong>Algorithmic perspective</strong>: This line of research designs the scalable and theoretically-grounded machine learning algorithms subject to real-life constraints, e.g., computation/communication overhead, robustness, fairness, and interpretability.</p>

<p><img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> <strong>Application perspective</strong>: This line of research tackles the domain-specific challenges to achieve scalable and trustworthy AI, e.g., robustness enhancement, fairness promotion, data privacy protection, and model compression.</p>

<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/research-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/research-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/research-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/research.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

<div class="caption">
  An overview of my research.
</div>

<h4 id="scalable-bi-level-optimization-theory-and-application">Scalable Bi-level Optimization: Theory and Application</h4>

<p>Bi-level optimization (BLO) has been emerged as a technology basis in solving many recent machine learning (ML) problems, such as attack and defense design in adversarial ML, meta learning, hyper-parameter optimization, and model pruning. My work focuses on reformulating existing ML problems and advancing their algorithmic foundations through theoretically-grounded, empirically outstanding and scalable BLO algorithms [<a href="#refer-anchor-2">2</a>, <a href="#refer-anchor-4">4</a>, <a href="#refer-anchor-8">8</a>].</p>

<p><strong>Scalable BLO algorithm and theory</strong></p>

<p>Compared to the conventional min-max problems, BLO offers us a unified hierarchical learning framework, where one task is nested inside the other (i.e., the objective and variables of an upper-level problem depend on the optimizer of the lower-level problem). Such a structure makes the BLO in its most generic form very difficult to solve and the hard to scale. Thus, I ask:</p>

<blockquote>
  <p>How to build theoretically-grounded BLO framework for ML problems with light computational complexity?</p>
</blockquote>

<p>My work [<a href="#refer-anchor-2">2</a>] proposed the first scalable BLO algorithm for robust training and my work [<a href="#refer-anchor-4">4</a>] also proposed a purely first-order BLO algorithm for model pruning, which achieves the best performance with much higher efficiency compared to the state-of-the-art baseline.</p>

<h4 id="trustworthy-ai-robustness-fairness-and-explanability">Trustworthy AI: Robustness, Fairness, and Explanability</h4>

<p>As researchers realize that solely high accuracy is not enough to make AI systems safe, responsible and worthy of the trust, the urge to build a <em>robust, fair, explainable</em> AI system has been described by some experts as the biggest challenges of the next 5 years [<a href="#refer-anchor-9">9</a>]. Thus, a large part of my work is dedicated to promote the robustness, fairness, and transparency of the AI system.</p>

<ul>
  <li>
    <p>Robustness: Adversarial training (AT) is one of the most famous methods to equip models with robustness, while it is also known for its intensive computational cost. To enable AT to support large datasets and model architectures, my work [<a href="#refer-anchor-1">1</a>] provides the first distributed robust training framework that scale up various robust training algorithms, including AT, certified training, and robust unsupervised training, which won the Best Paper Runner-up Award in UAI’22. Single-step AT is also an important branch of algorithms that serve to accelerate AT. Accordingly, my work [<a href="#refer-anchor-2">2</a>] advances the optimization foundation of accelerated AT through BLO and provides a promising solution with an attack-agnostic robust training framework. In the area of NLP, my work [<a href="#refer-anchor-6">6</a>] also proposed the first gradient-driven attack generator for language models, which successfully overcame the discrete nature of the textual input and the additional constraint of the perturbation. With the help of the newly designed attack, [<a href="#refer-anchor-6">6</a>] promoted the adversarial defense of NLP tasks to the next level.</p>
  </li>
  <li>
    <p>Fairness: My fairness reprogramming work [<a href="#refer-anchor-5">5</a>] achieved to promote the fairness of the models without changing the model weights in both NLP and CV tasks. I also achieved in reducing the model biases in the black-box setting, where only the outputs of the model API are accessible.</p>
  </li>
  <li>
    <p>Explanability: Trojan attack has also arisen as a real-world threaten to various ML systems. My work [<a href="#refer-anchor-3">3</a>] reveals why the backdoor works from the perspective of model compression and further proposes an effective data-free backdoor detection method.</p>
  </li>
</ul>

<center>
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bip-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bip-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bip-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/bip.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

</center>
<div class="caption">
  Bi-level optimization advances the algorithmic foundation of model pruning.
</div>

<h4 id="sparse-learning-for-model-compression">Sparse Learning for Model Compression</h4>

<p>Model sparsity has seen a lot of research interests these years, as reducing model size by removing redundant parameters has been known to benefit model generalization, adversarial robustness, out-of-distribution generalization, and transfer learning. My work [<a href="#refer-anchor-4">4</a>] reformulated the model pruning problem as a bi-level optimization problem, and proposed a theoretically-grounded algorithm, which achieves the new state-of-the-art performance and provides a whole new perspective for model pruning to the community. Sparsity can also help interpret backdoor attacks, as my work [<a href="#refer-anchor-3">3</a>] reveals that model pruning is more likely to remove the benign features compared to the backdoor features. Accordingly, I designed a clean data-free backdoor detection method leveraging model sparsity.</p>

<hr>

<h4 id="reference">Reference</h4>

<div id="refer-anchor-1"></div>
<p>[1] G. Zhang*, S. Lu*, <b>Y. Zhang</b>, X. Chen, P. Chen, Q. Fan, L. Martie, M. Hong, S. Liu, “Distributed Adversarial Training to Robustify Deep Neural Networks at Scale”, Conference on Uncertainty in Artificial Intelligence (UAI’22 - Best Paper Runner-up Award)</p>

<div id="refer-anchor-2"></div>
<p>[2] <b>Y. Zhang</b><em>, G. Zhang</em>, P. Khanduri, M. Hong, S. Chang, S. Liu, “Fast-BAT: Revisiting and Advancing Fast Adversarial Training through the Lens of Bi-level Optimization”, International Conference on Machine Learning (ICML’22)</p>

<div id="refer-anchor-3"></div>
<p>[3] T. Chen*, Z. Zhang*, <b>Y. Zhang</b>*, Chang, S. Liu, W. Yang, “Quarantine: Sparsity Can Uncover the Trojan Attack Trigger for Free”, Computer Vision and Pattern Recognition Conference (CVPR’22)</p>
<div id="refer-anchor-4"></div>
<p>[4] <b>Y. Zhang</b>*, Y. Yao*, P. Ram, P. Zhao, T. Chen, M. Hong, Y. Wang, S. Liu, “Advancing Model Pruning via Bi-level Optimization” (NeurIPS’22)</p>

<div id="refer-anchor-5"></div>
<p>[5]G. Zhang*, <b>Y. Zhang</b>*, Z. Zhang, W. Fan, Q. Li, S. Liu, S. Chang, “Fairness Reprogramming” (NeurIPS’22)</p>

<div id="refer-anchor-6"></div>
<p>[6 B. Hou, J. Jia, <b>Y. Zhang</b>, G. Zhang, Y. Zhang, S. Liu, S. Chang, “TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization” (ICLR’23)</p>

<div id="refer-anchor-7"></div>
<p>[7] H. Li, S. Zhang, M. Wang, <b>Y. Zhang</b>, P. Chen, S. Liu, “Theoretical Characterization of Neural Network Generalization with Group Imbalance” (under review)</p>

<div id="refer-anchor-8"></div>
<p>[8] P. Khanduri, I. Tsaknakis, <b>Y. Zhang</b>, J. Liu, S. Liu, J. Zhang, M. Hong, “Linearly Constrained Bilevel Optimization: A Smoothed Implicit Gradient Approach” (under review)</p>

<div id="refer-anchor-9"></div>
<p>[9] <b>Y. Zhang</b>, P. Sharma, P. Ram, M. Hong, K. R. Varshney, S. Liu, “What Is Missing in IRM Training and Evaluation? Challenges and Solutions “ (ICLR’23)</p>


          </article>

        </div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <center>
        <div id="clustrmaps-widget" style="width:10%">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=zP5RUg_lbda1vEJcVf6Y2wExCgt16XQuzyNJY2frl-I"></script>
        </div>
      <div class="container">
        © Copyright 2025 Yihua  Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>.
Last updated: July 12, 2025.
      </div>
      </center>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Enable Tooltips -->
  <script type="text/javascript">
  $(function () {$('[data-toggle="tooltip"]').tooltip()})
  </script>
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };

    window.MathJax = {
    tex: {
      tags: 'ams'
      inlineMath: [['$', '$'], ['\\(', '\\)'], ['!!', '!!']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <!-- <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$']]
        packages: ['base', 'newcommand', 'configMacros']
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script> -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

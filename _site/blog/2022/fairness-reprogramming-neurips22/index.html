<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>[NeurIPS22] Fairness Reprogramming | Yihua Zhang</title>
    <meta name="author" content="Yihua  Zhang" />
    <meta name="description" content="Don't waste your life. Don't waste it.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>☯️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/blog/2022/fairness-reprogramming-neurips22/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#155799">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/paper.css?v=">
  </head>

  <!-- Body -->
  <body class=" sticky-bottom-footer">

    <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Yihua Zhang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">Posts<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/collaboration/">Collaboration</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/photos/">Photos</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

    <header class="page-header" role="banner">
      <h1 class="project-name font-size:250%" style="color:white">[NeurIPS22] Fairness Reprogramming</h1>
      <br>
      <h2 class="project-tagline" style="color:white">
<a style="color: #dfebf7" href="https://ghzhang233.github.io/" target="_blank" rel="noopener noreferrer">Guanhua Zhang</a><sup>[1]</sup>*, <a style="color: #dfebf7" href="https://www.yihua-zhang.com/" target="_blank" rel="noopener noreferrer">Yihua Zhang</a><sup>[2]</sup>*, <a style="color: #dfebf7" href="https://https://scholar.google.com/citations?hl=zh-CN&amp;user=_-5PSgQAAAAJ/" target="_blank" rel="noopener noreferrer">Yang Zhang</a><sup>[3]</sup>, <a style="color: #dfebf7" href="https://wenqifan03.github.io/" target="_blank" rel="noopener noreferrer">Wenqi Fan</a><sup>[4]</sup>, <a style="color: #dfebf7" href="https://scholar.google.com/citations?hl=zh-CN&amp;user=XRB2rKIAAAAJ" target="_blank" rel="noopener noreferrer">Qing Li</a><sup>[4]</sup>, <a style="color: #dfebf7" href="https://lsjxjtu.github.io/" target="_blank" rel="noopener noreferrer">Sijia Liu</a><sup>[2,4]</sup>
</h2>
      <h2 class="project-tagline" style="color:white">
<sup>[1]</sup>University of Santa Barbara, <sup>[2]</sup>Michigan State University, <sup>[3]</sup>MIT-IBM Watson AI Lab, <sup>[4]</sup>The Hong Kong Polytechnic University</h2>
      
      <a href="https://arxiv.org/pdf/2209.10222.pdf" class="btn" target="_blank" rel="noopener noreferrer">Paper</a>
      
      
      <a href="https://github.com/OPTML-Group/Fairness-Reprogramming" class="btn" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      <a href="https://www.yihua-zhang.com/assets/posters/fairness_reprogramming.pdf" class="btn" target="_blank" rel="noopener noreferrer">Poster</a>
      
      
      
      
      
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <h3 id="overview">Overview</h3>

<p>In this paper, we propose a new generic fairness learning paradigm,
called fairness reprogramming:</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/overview-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/overview-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/overview-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/overview.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Dilemma in Pruning" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 1. An example of fairness reprogramming in CV and NLP tasks. The input agnostic trigger can promote fairness without altering the pretrained model.
</div>

<hr>

<h3 id="principal-research-question">Principal Research Question</h3>

<center>
<b>
Can an unfair model be reprogrammed into a fair one? <br> If so, why and how would it work?
</b>
<br>
</center>

<hr>

<h3 id="fairness-reprogramming">Fairness Reprogramming</h3>

<p>Consider a classification task, where \(\mathbf{X}\) represents the input feature and \(Y\) represents the output label. There exists some sensitive attributes or demographic groups, \(Z\), that may be spuriously
correlated with \(Y\). There is a pre-trained classifier, \(f^*(\cdot)\) that predicts \(Y\) from \(\mathbf{X}\), <em>i.e.</em>, \(\hat{Y} = f^*(\mathbf{X})\).</p>

<p>The goal of fairness reprogramming is to improve the fairness of the classifier by modifying the input \(\mathbf{X}\), while keeping the classifier’s weights \(\boldsymbol\theta\) fixed. In particular, we aim to achieve either of the following fairness criteria.</p>

<ul>
  <li>Equalized Odds:</li>
</ul>

\[\hat{Y} \perp Z | Y,\]

<ul>
  <li>Demographic Parity:</li>
</ul>

\[\hat{Y} \perp Z,\]

<p>where \(\perp\) denotes independence.</p>

<h4 id="fairness-trigger">Fairness Trigger</h4>

<p>The reprogramming primarily involves appending a fairness trigger to the input. Formally, the input modification takes the following generic form:</p>

\[\tilde{\mathbf{X}} = m(\mathbf{X}; \boldsymbol\theta, \boldsymbol \delta) = [\boldsymbol \delta, g(\mathbf{X}; \boldsymbol\theta)],\]

<p>where \(\tilde{\mathbf{X}}\) denotes the modified input; \([\cdot]\) denotes vector concatenation (see Figure 1).</p>

<h4 id="optimization-objective-and-discriminator">Optimization Objective and Discriminator</h4>

<p>Our optimization objective is as follows</p>

\[\min_{\boldsymbol\theta, \boldsymbol\delta} \,\,\, \mathcal{L}_{\text{util}} (\mathcal{D}_{\text{tune}}, f^* \circ m) + \lambda \mathcal{L}_{\text{fair}} (\mathcal{D}_{\text{tune}}, f^* \circ m),\]

<p>where \(\mathcal{D}_{\text{tune}}\) represents the dataset that is used to train the fairness trigger. The first loss term, \(\mathcal{L}_{\text{util}}\), is the utility loss function of the task. For classification tasks, \(\mathcal{L}_{\text{util}}\) is usually the cross-entropy loss, <em>i.e.</em>,:</p>

\[\mathcal{L}_{\text{util}}(\mathcal{D}_{\text{tune}}, f^* \circ m) = \mathbb{E}_{\mathbf{X}, Y \sim \mathcal{D}_{\text{tune}}} [\textrm{CE}(Y, f^*(m(\mathbf{X})))],\]

<p>The second loss term, \(\mathcal{L}_{fair}\), encourages the prediction to follow the fairness criteria and should measure how much information about \(Z\) is in \(\hat{Y}\). Thus, we introduce another network, the discriminator, \(d(\cdot; \boldsymbol \phi)\), where \(\boldsymbol \phi\) represents its parameters. If the equalized odds criterion is applied,  then \(d(\cdot; \boldsymbol \phi)\) should predict \(Z\) from \(\hat{Y}\) and \(Y\); if the demographic parity criterion is applied, then the input to \(d(\cdot; \boldsymbol \phi)\) would just be \(\hat{Y}\). The information of \(Z\) can be measured by maximizing the <em>negative</em> cross-entropy loss for the prediction of \(Z\) over the discriminator parameters:</p>

\[\mathcal{L}_{\text{fair}} (\mathcal{D}_{\text{tune}}, f^* \circ m) = \max_{\boldsymbol \phi} \mathbb{E}_{\mathbf{X}, Y, Z \sim \mathcal{D}_{\text{tune}}} [-\textrm{CE}(Z, d(f^*(m(\mathbf{X})), Y; \boldsymbol \phi))].\]

<p>We give an illustration of our fairness reprogramming algorithm below, which co-optimizes the fairness trigger and the discriminator at the same time in a min-max fashion.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-1">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/algorithm-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/algorithm-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/algorithm-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/algorithm.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Algorithm." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 2. An illustration of our proposed fairness reprogramming algorithm.
</div>

<h3 id="experiment-results">Experiment results</h3>

<p>We consider the following two commonly used NLP and CV datasets:</p>

<ul>
  <li>
    <p>Civil Comments: The dataset contains 448k texts with labels that depict the toxicity of
each input. The demographic information of each text is provided.</p>
  </li>
  <li>
    <p>CelebA: The dataset contains over 200k human face images and each contains 39 binary
attribute annotations. We adopt the hair color prediction task in our experiment and use gender annotation as the demographic information.</p>
  </li>
</ul>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/main_results-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/main_results-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/main_results-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/main_results.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Main results." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 3. Results on (a) Civil Comments and (b) CelebA. We report the negative DP (left) and the negative EO (right) scores. For each method, we vary the trade-off parameter λ to record the performance. The closer a dot is to the upper-right corner, the better the model is. 
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/tuning_ratio-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/tuning_ratio-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/tuning_ratio-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/tuning_ratio.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Tuning ratio." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 4. Results on (a) Civil Comments and (b) CelebA with different tuning data ratios. We report the negative DP (left) and negative EO (right) scores. We consider a fixed BASE model trained with a training set, whose negative bias scores are presented as a black dashed line. Then we train other methods with different tuning data ratios to promote fairness of the BASE model.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/transfer-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/transfer-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/transfer-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/transfer.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Transfer setting." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 5. Results in the transfer setting. We report negative DP (left) and negative EO (right) scores. The triggers are first trained in a BASE model. Then, we evaluate the triggers based on another unseen BASE model. We change the parameter λ to trade off accuracy with fairness and draw the curves in the same way as Figure 3.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/multi_class-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/multi_class-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/multi_class-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/multi_class.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Multi-class setting." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 6. Performance of multi-class classification. For (a) and (b), we use the attributes Blond Hair, Smiling, and Attractive for multi-class construction. We add an additional attribute Wavy Hair for (c) and (d).
</div>

<hr>

<h3 id="why-does-fairness-trigger-work">Why does Fairness Trigger work?</h3>

<p>In our paper, we both theoretically prove and empirically demonstrate why a <em>global trigger</em> can obscure the demographic information for <em>any</em> input. In general, the trigger learned by the reprogrammer contains very strong demographic information and blocks the model from relying on the real demographic information from the input. Since the same trigger is attached to all the input, the uniform demographic information contained in the trigger will weaken the dependence of the model on the true demographic information contained in the data, and thus improve the fairness of the pretrained model.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/why_works-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/why_works-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/why_works-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/why_works.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Trigger demographic information." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 7. Illustration of why fairness trigger works. (a) The data generation process. (b) The information flow from data to the classifier through sufficient statistics. (c) A fairness trigger strongly indicative of a demographic group can confuse the classifier with a false demographic posterior, thus preventing the classifier from using the correct demographic information.
</div>

<h4 id="input-saliency-analysis">Input Saliency Analysis</h4>

<p>The following two figures compare the saliency maps of some example inputs with and without the fairness triggers. Specifically, For the NLP applications, we extract a subset of Civil
Comments with religion-related demographic annotations, and apply IG to localize word pieces
that contribute most to the text toxicity classification. For the CV application, we use GradCam to identify class-discriminative regions of CelebA’s test images.</p>

<p>Figure 8 presents the input saliency maps on two input images with respect to their predicted labels, non-blond hair and blond hair, respectively. When there is no fairness trigger, the saliency region incorrectly concentrates on the facial parts, indicating the classifier is likely to use biased information, such as gender, for its decision. With the fairness trigger, the saliency region moves to the hair parts.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/gradcam-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/gradcam-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/gradcam-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/gradcam.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Grad Cam." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 8. Gradient-based saliency map visualized with GradCam [\[1\]](#refer-anchor-1) of different methods. The highlighted zones (marked in red) depicting regions exerting major influence on the predicted labels (non-blond hair v.s. blond hair) in each row, which also depict the attention of the model on the input image.
</div>

<p>In Figure 9, our fairness trigger consists of a lot of religion-related words (e.g., diocesan, hebrew, parish). Meanwhile, the predicted toxicity score of the benign text starting from ‘muslims’ significantly reduces. These observations verify our theoretical hypothesis that the fairness trigger is strongly indicative of a certain demographic group to prevent the classifier from using the true demographic information.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/integrated_grad-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/integrated_grad-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/integrated_grad-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/integrated_grad.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Integrated Gradient." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 9. A text example from Civil Comments with Integrated Gradient [\[2,3\]](#refer-anchor-2) highlighting important words that influence ERM model predictions. The text is concatenated with three triggers generated with different adversary weights. Green highlights the words that lean toward toxic predictions and red highlights non-toxic leaning words. The model prediction tends to be correct after adding the triggers.
</div>

<p>To further verify that the triggers encode demographic information, we trained a demographic classifier to predict the demographics from the input (texts or images). We use the demographic classifier to predict the demographic information of a null image/text with the trigger. We see that the demographic classifier gives confident outputs on the triggers, indicating that they found triggers are highly indicative of demographics.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/fairness_nips22/demographic_info_trigger-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/fairness_nips22/demographic_info_trigger-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/fairness_nips22/demographic_info_trigger-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/posts/fairness_nips22/demographic_info_trigger.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Trigger demographic information." data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="color: #999; font-size:16px; padding: 2px;">
    Figure 10. Predictions of the demographic classifier on a null input with triggers generated by different λ. The demographic prediction for CV triggers indicate the predicted score for Male and Female, and it is Christian, Muslim, and other religion for NLP.
</div>

<hr>

<h3 id="citation">Citation</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td>
<td class="rouge-code"><pre>@inproceedings{zhang2022fairness,
  title = {Fairness reprogramming},
  author = {Zhang, Guanhua and Zhang, Yihua and Zhang, Yang and Fan, Wenqi and Li, Qing and Liu, Sijia and Chang, Shiyu},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2022}
}
</pre></td>
</tr></tbody></table></code></pre></div></div>
<hr>

<h3 id="reference">Reference</h3>

<div id="refer-anchor-1"></div>
<p>[1] Ramprasaath R Selvaraju et al. “Grad-cam: Visual explanations from deep networks via gradient-based localization” ICCV 2017.</p>

<div id="refer-anchor-2"></div>
<p>[2] Mukund Sundararajan et al. “Axiomatic attribution for deep networks” ArXiv, vol. abs/1703.01365, 2017.</p>

<div id="refer-anchor-3"></div>
<p>[3] Narine Kokhlikyan et al. “Captum: A unified and generic model interpretability library for PyTorch” arXiv preprint arXiv:2009.07896.</p>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <center>
        <div id="clustrmaps-widget" style="width:10%">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=zP5RUg_lbda1vEJcVf6Y2wExCgt16XQuzyNJY2frl-I"></script>
        </div>
      <div class="container">
        © Copyright 2025 Yihua  Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>.
Last updated: July 12, 2025.
      </div>
      </center>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Enable Tooltips -->
  <script type="text/javascript">
  $(function () {$('[data-toggle="tooltip"]').tooltip()})
  </script>
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };

    window.MathJax = {
    tex: {
      tags: 'ams'
      inlineMath: [['$', '$'], ['\\(', '\\)'], ['!!', '!!']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <!-- <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$']]
        packages: ['base', 'newcommand', 'configMacros']
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script> -->
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
